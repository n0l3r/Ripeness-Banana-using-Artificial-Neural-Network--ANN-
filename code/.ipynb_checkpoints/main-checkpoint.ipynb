{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import glob\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = '../dataset/'\n",
    "IMAGE_WIDTH = 533\n",
    "IMAGE_HEIGHT = 300\n",
    "# read all images in the folder dataset\n",
    "labels = ['mentah', 'matang']\n",
    "images = []\n",
    "for label in labels:\n",
    "    for file in tqdm(glob.glob(dataset + label + '/*.jpg')):\n",
    "        img = cv2.imread(file)\n",
    "        img = cv2.resize(img, (IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "        img_array = np.array(img)\n",
    "        images.append([img_array, label])\n",
    "print(len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv2_show(img):\n",
    "    cv2.imshow('image', img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def gaussian_blur(img):\n",
    "    return cv2.GaussianBlur(img, (3, 3), 0)\n",
    "\n",
    "def hsv(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "def mask(img, label):\n",
    "    if label == 'mentah':\n",
    "        lower = np.array([0, 66, 0])\n",
    "        upper = np.array([255, 255, 255])\n",
    "    else:\n",
    "        lower = np.array([0, 41, 0])\n",
    "        upper = np.array([255, 255, 255])\n",
    "    return cv2.inRange(img, lower, upper)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2_show(images[0][0])\n",
    "\n",
    "# blur all images\n",
    "blur_images = []\n",
    "\n",
    "for i in range(len(images)):\n",
    "    blur_images.append([gaussian_blur(images[i][0]), images[i][1]])\n",
    "    \n",
    "cv2_show(blur_images[0][0])\n",
    "\n",
    "# convert to hsv\n",
    "hsv_images = []\n",
    "\n",
    "for i in range(len(blur_images)):\n",
    "    hsv_images.append([hsv(blur_images[i][0]), images[i][1]])\n",
    "\n",
    "cv2_show(hsv_images[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask all images\n",
    "mask_images = []\n",
    "\n",
    "for i in range(len(images)):\n",
    "    mask_images.append([mask(hsv_images[i][0], images[i][1]), images[i][1]])\n",
    "\n",
    "cv2_show(mask_images[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# erosion and dilation\n",
    "\n",
    "segmented_images = []\n",
    "\n",
    "for mask in mask_images:\n",
    "    kernel = np.ones((3, 3),np.uint8)\n",
    "    erosion = cv2.erode(mask[0], kernel,iterations = 1)\n",
    "    dilation = cv2.dilate(erosion,kernel,iterations = 1)\n",
    "    segmented_images.append([dilation, mask[1]])\n",
    "\n",
    "cv2_show(segmented_images[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final images v1\n",
    "final_images = []\n",
    "\n",
    "for i in range(len(segmented_images)):\n",
    "    final_images.append([cv2.bitwise_and(images[i][0], images[i][0], mask=segmented_images[i][0]), images[i][1]])\n",
    "\n",
    "# masih terdapat sisa-sisa background\n",
    "cv2_show(final_images[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_blur_v2(img):\n",
    "    return cv2.GaussianBlur(img, (15, 15), 3)\n",
    "\n",
    "def mask_v2(img, label):\n",
    "    if label == 'mentah':\n",
    "        lower = np.array([0, 100, 0])\n",
    "        upper = np.array([255, 255, 255])\n",
    "    else:\n",
    "        lower = np.array([0, 95, 0])\n",
    "        upper = np.array([255, 255, 255])\n",
    "    return cv2.inRange(img, lower, upper)\n",
    "\n",
    "segmented_images_v2 = []\n",
    "\n",
    "for image in images:\n",
    "    img = gaussian_blur_v2(image[0])\n",
    "    img = hsv(img)\n",
    "    img = mask_v2(img, image[1])\n",
    "\n",
    "    kernel = np.ones((3, 3),np.uint8)\n",
    "    if image[1] == 'mentah' :\n",
    "        erosion = cv2.erode(img, kernel,iterations = 1)\n",
    "        dilation = cv2.dilate(erosion,kernel,iterations = 1)\n",
    "    else:\n",
    "        erosion = cv2.erode(img, kernel,iterations = 2)\n",
    "        dilation = cv2.dilate(erosion,kernel,iterations = 1)\n",
    "    segmented_images_v2.append([dilation, image[1]])\n",
    "\n",
    "final_images_v2 = []\n",
    "for i in range(len(final_images)):\n",
    "    final_images_v2.append([cv2.bitwise_and(images[i][0], images[i][0], mask=segmented_images_v2[i][0]), images[i][1]])\n",
    "cv2_show(segmented_images_v2[0][0])\n",
    "cv2_show(final_images_v2[0][0])\n",
    "len(final_images_v2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all final images v2 to file system\n",
    "for i in range(len(final_images_v2)):\n",
    "    cv2.imwrite('../dataset/segmented/' + final_images_v2[i][1] + '/' + str(i) + '.jpg', final_images_v2[i][0])\n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access all segmented images\n",
    "segmented_images = []\n",
    "for label in labels:\n",
    "    for file in tqdm(glob.glob('../dataset/segmented/' + label + '/*.jpg')):\n",
    "        img = cv2.imread(file)\n",
    "        img = cv2.resize(img, (IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "        img_array = np.array(img)\n",
    "        segmented_images.append([img_array, label])\n",
    "\n",
    "print(len(segmented_images))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rgb(img):\n",
    "    r = np.mean(img[:,:,2])\n",
    "    g = np.mean(img[:,:,1])\n",
    "    b = np.mean(img[:,:,0])\n",
    "    return [r, g, b]\n",
    "\n",
    "means = []\n",
    "for image in segmented_images:\n",
    "    rgb = get_rgb(image[0])\n",
    "    means.append([rgb[0], rgb[1], rgb[2], image[1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to dataframe\n",
    "# Red, Green, Blue, Label\n",
    "df = pd.DataFrame(means, columns=['Red', 'Green', 'Blue', 'Label'])\n",
    "# show all data\n",
    "df.head(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to csv\n",
    "df.to_csv('../dataset/segmented/segmented.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change label to number\n",
    "df['Label'] = df['Label'].map({'mentah': 0, 'matang': 1})\n",
    "\n",
    "# show all data\n",
    "df.head(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot target distribution\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.countplot(x='Label', data=df)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sebaran data warna histogram\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.hist(df['Red'], bins=10, color='red', alpha=0.5)\n",
    "plt.title('Red')\n",
    "plt.grid(True)\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.hist(df['Green'], bins=10, color='green', alpha=0.5)\n",
    "plt.title('Green')\n",
    "plt.grid(True)\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.hist(df['Blue'], bins=10, color='blue', alpha=0.5)\n",
    "plt.title('Blue')\n",
    "plt.grid(True)\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.hist(df['Label'], bins=10, color='black', alpha=0.5)\n",
    "plt.title('Label')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split to train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['Red', 'Green', 'Blue']], df['Label'], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.05)\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(3, kernel_initializer='uniform', activation='relu', input_dim=3))\n",
    "model.add(tf.keras.layers.Dense(30, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=10, epochs=1000, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, acc = model.evaluate(X_test, y_test, batch_size=10)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save('../model/final_acc_100.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "score, acc = model.evaluate(X_test, y_test, batch_size=10)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# plot confusion matrix\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.title('Confusion matrix')\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
